# Quora-Question-Pair-Similarity-Project
A NLP Project.

According to Quora, It is a place to gain & share knowledge, It’s a platform to ask questions & connect with people who contribute insights & quality answers. In other words, Quora is a question-answering website where people can visit the website and find information. On Quora every piece of content is generated by users, that is, it is created, edited & organized by the same people that use the website.

Currently, Quora is facing the issue of Duplicate questions. For instance, consider a pair of questions as follows:

for example:-
	    Question1: What should I do to be a great Geologist?
	    Question2: How can I be a good Geologist?
2 questions are talking about the same thing. Now the challenge for Quora is to eliminate the question pairs that are duplicates of each other.
So that someone does not have to re-write the same answer for the same question asked differently.
This way Quora can enhance the customer experience & reduce the unanswered duplicate questions & thus saving a lot of time for the users.

Data Description
	csv file:quora_train.csv
	features : id, question1 id (qid1), question2 id (qid2), question1, question2, is_duplicate (target feature to predict).

Evaluation metric
	The model performance of the participants will be evaluated using Binary Log-Loss. The minimum the log loss is the better.

Number of Observations and Columns present in the Training Dataset are (404290, 6)

There are 2 columns with very few questions missing in the training dataset.

Observation:
	There are roughly 63% of the question pairs that are not similar to each other. While roughly 37% of the question pairs are similar/duplicates of each other. Hence, we conclude that Is_duplicate is imbalanced but not to a high degree.
	
Feature Extraction (basic):
    a) Length of Question1.

    b) Length of Question2.

    c) Total number of words present in Question1.

    d)Total number of words present in Question2.

    e) Number of words that are common to Question1 & Question2.

    f) Total number of words in Question1 & Question2.

    g) Word-Share = (Number of Common words in Question1 & Question2)/(Total number of Words present in Question1 & Question2)


	Observations:

    1) We see distribution of Length of Question1 & Question2 are Overlapping for duplicate & Non-duplicate Question Pairs. So these features may not be useful in separating the duplicate & non-duplicate question pairs. Hence, we would drop them from modelling.

    2) Word-Share feature’s Probability Density functions for duplicate & non-duplicate question pairs are not only non-overlapping to each other. But we also observe that for duplicate question pairs the number of common words (indicated by higher value of word-share) is higher (indicated by 1 relative to total number of words present in Question1 & Question2 pairs). While for Non-Duplicated question pairs (indicated by 0) has lower word-share ratio (indicating less number of common words in question1 & question2 relative o total number of words present in question1 & question2 pairs). This is inferred from the violinplot of word-share feature vs. is_duplicate.

    3) Number of words in question1 for duplicate & non-duplicate question pairs have an overlapping distributions which suggests that this feature might be useless for classifying the question pairs to be either duplicate or non-duplicate.

    4) Same holds true for number of words in question2, number of common words in question1 & question2 and number of total words in question1 & question2 features.


Text Preprocessing
As part of Text preprocessing/Cleaning I performed 3 steps:

    a) Converting texts into lowercase (for Question1 & Question2)

    b) Contraction to Expansion: i.e., Word’s like “ain’t” is converted to “am not” & “can’t” is converted to “cannot”. Also, after exploration of some question pairs. We found that some symbols like “%”, “€”, etc. are replaced with words to “percent”, “euro”.

    c) Lastly, after exploration we found some question pairs have HTML Tags hence we decided to remove them.

Feature Extraction (advanced):

	terminologies:
	    a) Token : Any word after splitting the sentences we get are defined as token.

    	    b) Stopword : A stopword is a word that does not contributes anything meaningful in NLP.

   	    c) Word : A word is defined as a token that is not a stopword.

	Extracting some more NLP based features :

    a) cwc_min : It is defined as Ratio of (Total number of common words in Question1 & Question2) & (Minimum length of words in question1 & question2).

    b) cwc_max : It is defined as Ratio of (Total number of common words in Question1 & Question2) & (Maximum length of words in question1 & question2).

    c) csc_min : It is defined as Ratio of (Total number of common stopwords in Question1 & Question2) & (Minimum length of stopwords in question1 & question2).

    d) csc_max : It is defined as Ratio of (Total number of common stopwords in Question1 & Question2) & (Maximum length of stopwords in question1 & question2).

    e) ctc_min : It is defined as Ratio of (Total number of common tokens in Question1 7 Question2) & (Minimum length of tokens in question1& question2).

    f) ctc_max : It is defined as Ratio of (Total number of common tokens in Question1 7 Question2) & (Maximum length of tokens in question1& question2)

Now creating some fuzzy NLP features using a popular library FuzzyWuzzy

    a) fuzz_ratio

    b) fuzz_partial_ratio

    c) token_set_ratio

    d) token_sort_ratio

Observations

    a) All of these fuzzy based ratios are higher for duplicate question pairs relative to non-duplicate question pairs.

    b) By looking at the distribution (rather than pairplots) of rest of the created features, except word mover’s distance & normalized word mover’s distance, we observe that the cwc_min ratio is higher for duplicate question pairs, similarly for ctc_min, cwc_max & ctc_max. While csc_min & csc_max are more or less have similar distribution for duplicate 7 non-duplicate question pairs

Featurizing text data with tfidf weighted word-vectors
	. tf–idf or TFIDF, short for term frequency–inverse document frequency, is a numerical way of vectorizing text data that is intended to reflect how important a word is to a document in a collection or corpus.


Machine Learning Models
	Support Vector Classifier
		We have used LinearSVC because it is recommended for large datasets. We have used the L2 penalty and the loss function is squared of hinge loss. Also, it is recommended to use primal formulation for large datasets. For some values of C it was not conversing so I increased max_iter to 3000.
	
	Random Forest
		we are using halving grid search cv . And the best accuracy is 90.53%. So the accuracy has increased by 5% as compared to SVM.
	
	XGBoost
		Due to time and system configuration constrained, I decided to use 200000 data points to estimate a few of the params.
	

Conclusion
In the future, we can try some deep learning-based models.

		
